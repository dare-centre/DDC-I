{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DARE Deluxe Data Challenge I\n",
    "DARE 2023\n",
    "\n",
    "In this notebook, we will provide a template for the DARE Deluxe Data Challenge. The main steps covered here will be:\n",
    "\n",
    "- Load the data\n",
    "- Provide an overview of what is in the data\n",
    "- Provide an example of a terribly performing baseline model\n",
    "- Provide functions to quantify model predictive performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False\n",
    "if colab:\n",
    "    !git clone https://github.com/dare-centre/DDC-I\n",
    "    import os\n",
    "    os.chdir('DDC-I')\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb 0\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings\n",
    "Everything we need to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# plotting\n",
    "from functions.plotting_functions import (plot_model_fit) \n",
    "# helper\n",
    "from functions.helper_functions import (assess_model_prediction, inversescaler_pred_dict)\n",
    "# data\n",
    "from functions.data_functions import(load_hourly_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_x, train_val_y, test_x_all, test_y = load_hourly_data()\n",
    "\n",
    "train_val_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at some properties of the data \n",
    "print('Number of features: {}'.format(train_val_x.shape[1]))\n",
    "print('Number of training observations: {}'.format(train_val_x.shape[0]))\n",
    "print('Number of test observations: {}'.format(test_x_all.shape[0]))\n",
    "print('Feature names: {}'.format(test_x_all.columns.tolist()))\n",
    "print('Predict variable: {}'.format(train_val_y.columns.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split our training data into training and validation sets\n",
    "We can either split this randomly if we are just modelling as a plain regression problem (set `shuffle = True`), or we can split it sequentially if we are modelling as a time series problem (set `shuffle = False`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly or sequentially split the data into training and validation sets\n",
    "val_split = False # there is no benefit to using a validation in our simple linear model\n",
    "shuffle = True\n",
    "\n",
    "if val_split:\n",
    "    train_x_all, val_x_all, train_y, val_y = train_test_split(train_val_x, train_val_y, test_size=0.2, shuffle=shuffle)\n",
    "else:\n",
    "    train_x_all = train_val_x\n",
    "    train_y = train_val_y\n",
    "    val_x_all = None\n",
    "    val_y = None\n",
    "\n",
    "# create placeholders for our model predictions\n",
    "train_y_pred = None\n",
    "val_y_pred = None\n",
    "test_y_pred = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select predictors\n",
    "We will use the very simplistic approach of just assessing the correlation to the target variable and selecting the most useful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 5 # select the top n features - use None for all features\n",
    "\n",
    "if top_n is not None:\n",
    "    ## YOUR CODE HERE\n",
    "    # you can use your own code here to find the optimal features\n",
    "\n",
    "    # example with simpler correlation approach\n",
    "    # select the top n features\n",
    "    corr_df = pd.concat([train_x_all, train_y], axis=1).corr().abs()\n",
    "    # print the top n predictors\n",
    "    print(corr_df.sort_values(ascending=False).head(top_n))\n",
    "    top_n_features = corr_df.sort_values(ascending=False).head(top_n).index.tolist()\n",
    "    ## END CODE\n",
    "else:\n",
    "    # use all features\n",
    "    top_n_features = train_x_all.columns.tolist()\n",
    "\n",
    "# Now \n",
    "train_x = train_x_all[top_n_features]\n",
    "train_time = train_x_all.index\n",
    "test_x = test_x_all[top_n_features]\n",
    "test_time = test_x_all.index\n",
    "if val_split:\n",
    "    val_x = val_x_all[top_n_features]\n",
    "    val_time = val_x_all.index\n",
    "else:\n",
    "    val_x = None\n",
    "    val_time = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the data if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_scaler = True\n",
    "\n",
    "if use_scaler:\n",
    "    # standardise the data for better performance\n",
    "    scaler_x = StandardScaler()\n",
    "    train_x = scaler_x.fit_transform(train_x)\n",
    "    test_x = scaler_x.transform(test_x)\n",
    "    if val_split:\n",
    "        val_x = scaler_x.transform(val_x)\n",
    "\n",
    "    scaler_y = StandardScaler()\n",
    "    train_y = scaler_y.fit_transform(train_y)\n",
    "    test_y = scaler_y.transform(test_y)\n",
    "    if val_split:\n",
    "        val_y = scaler_y.transform(val_y)\n",
    "\n",
    "else:\n",
    "    scaler_x = None\n",
    "    scaler_y = None\n",
    "    # easier if they're all numpy arrays from this point in\n",
    "    train_x = train_x.values\n",
    "    test_x = test_x.values\n",
    "    if val_split:\n",
    "        val_x = val_x.values\n",
    "    train_y = train_y.values\n",
    "    test_y = test_y.values\n",
    "    if val_split:\n",
    "        val_y = val_y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "We will use a simple linear regression model as a baseline. You can implement your own model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "# fit a linear model to the data\n",
    "model = lm.LinearRegression()\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "# fit a neural network to the data\n",
    "# model = MLPRegressor(\n",
    "#     hidden_layer_sizes=(100,20), max_iter=1000,\n",
    "#     activation='relu', solver='adam',\n",
    "# )\n",
    "# model.fit(train_x,train_y.squeeze())\n",
    "\n",
    "# predict on data\n",
    "train_y_pred = model.predict(train_x)\n",
    "test_y_pred = model.predict(test_x)\n",
    "if not val_x is None:\n",
    "    val_y_pred = model.predict(val_x)\n",
    "\n",
    "## END CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess model performance\n",
    "\n",
    "When calling the `assess_model_prediction`, we will leave `test=False` so that the test data are unseen (honesty system!) until the end of the data challenge. This is to ensure that we don't just overfit the model to the test data. When making your final model run, please set `test=True` to get a final assessment of your model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dict of data for plotting and metrics\n",
    "data_dict = {\n",
    "    'train_time': train_time,\n",
    "    'train_y': train_y,\n",
    "    'train_y_pred': train_y_pred,\n",
    "    'test_time': test_time,\n",
    "    'test_y': test_y,\n",
    "    'test_y_pred': test_y_pred,\n",
    "    'val_time': val_time,\n",
    "    'val_y': val_y,\n",
    "    'val_y_pred': val_y_pred,\n",
    "}\n",
    "predicted_data  = inversescaler_pred_dict(data_dict, scaler=scaler_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model performance and get metrics\n",
    "metrics = assess_model_prediction(predicted_data,test=False)\n",
    "print('Model performance metrics:')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f532f3807191c22baaed3ff97e55a43c45b25332d3cba4cee14c260dd9338ea7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
